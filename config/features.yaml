# AI Technology Feature Flags Configuration
# All features are DISABLED by default for backward compatibility
# Enable features progressively as needed

features:
  # PyTorch Lightning - 10x faster multi-GPU training
  pytorch_lightning:
    enabled: false                          # Default: OFF
    services: 
      - "image-generation"
      - "video-generation"
    description: "Accelerated training with PyTorch Lightning"
    fallback_to_legacy: true                # Use original PyTorch if Lightning fails
  
  # vLLM - 24x faster LLM inference
  vllm_inference:
    enabled: false                          # Default: OFF
    fallback_to_legacy: true                # Use original inference if vLLM fails
    model: "meta-llama/Llama-3-8b"
    description: "Ultra-fast large language model inference"
  
  # LangChain - LLM orchestration framework
  langchain_orchestration:
    enabled: false                          # Default: OFF
    optional: true                          # Completely optional service
    description: "Advanced LLM workflow orchestration"
  
  # ONNX Runtime - Cross-platform inference optimization
  onnx_export:
    enabled: false                          # Default: OFF
    models: []                              # List of models to export
    description: "Export models to ONNX format for cross-platform deployment"
  
  # JAX - High-performance scientific computing
  jax_acceleration:
    enabled: false                          # Default: OFF
    experimental: true                      # Experimental feature
    services:
      - "crypto-prediction"
    description: "JAX-based acceleration for numerical computing"
  
  # TensorFlow 3.0 - Alternative backend
  tensorflow_backend:
    enabled: false                          # Default: OFF
    alternative_backend: true               # Alternative to PyTorch
    description: "TensorFlow 3.0 as alternative AI backend"
  
  # Haystack - RAG & semantic search
  haystack_search:
    enabled: false                          # Default: OFF
    optional: true                          # Optional service
    description: "Retrieval-Augmented Generation and semantic search"
  
  # Rust AI Bindings - High-performance inference
  rust_ai_bridge:
    enabled: false                          # Default: OFF
    experimental: true                      # Experimental feature
    libraries:
      - "burn-rs"
      - "candle"
      - "tract"
    description: "Rust-based high-performance AI inference"

# API Version Configuration
api:
  v1:
    enabled: true                           # V1 always enabled
    default: true                           # V1 is default
  v2:
    enabled: false                          # V2 opt-in only
    fallback_to_v1: true                    # Automatic fallback to V1

# Performance & Safety Settings
safety:
  graceful_degradation: true                # Always fallback to legacy on failure
  backward_compatibility_checks: true       # Validate backward compatibility
  feature_flag_override: false              # Allow environment variable override

# Logging & Monitoring
monitoring:
  log_feature_usage: true                   # Log which features are used
  performance_metrics: true                 # Track performance improvements
  error_tracking: true                      # Track errors in new features
